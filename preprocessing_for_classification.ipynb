{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e308fe-d8f4-4e01-aa0e-de6997836209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.applications import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import csv\n",
    "import cv2\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall ,F1Score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e831beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"Combined_images\"\n",
    "image_list = []\n",
    "file_names = []\n",
    "\n",
    "# Iterate over each file in the specified directory\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(('.jpg', '.png', '.tif', '.JPG')):\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        img = cv2.imread(file_path)\n",
    "        # Append the image and its filename to the lists\n",
    "        image_list.append(img)\n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0d8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the number from the image filename\n",
    "def extract_number_from_filename(filename):\n",
    "    # Assuming the number is after 'combined_' and before the first '.'\n",
    "    return filename.split('_')[1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c50041",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file_names = []\n",
    "for name in file_names:\n",
    "    clean_file_names.append(extract_number_from_filename(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7892d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (replace these with your actual data)\n",
    "images = image_list\n",
    "image_names = clean_file_names\n",
    "\n",
    "# Function to read the CSV and create a dictionary of image names to labels\n",
    "def read_csv_to_dict(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract image names and labels\n",
    "    image_names = df.iloc[:, 0].values\n",
    "    labels = df.iloc[:, -1].values\n",
    "\n",
    "    # Create a list of image-label pairs\n",
    "    image_label_array = np.array([[name, label] for name, label in zip(image_names, labels)])\n",
    "    \n",
    "    # Convert the NumPy array to a dictionary\n",
    "    image_label_dict = {row[0]: row[1] for row in image_label_array}\n",
    "    return image_label_dict\n",
    "\n",
    "\n",
    "# Function to create the list of images and their corresponding labels\n",
    "def create_image_label_list(images, image_names, image_label_dict):\n",
    "    image_label_list = []\n",
    "    for image, name in zip(images, image_names):\n",
    "        if name in image_label_dict:\n",
    "            label = image_label_dict[name]\n",
    "            image_label_list.append([name,image, label])\n",
    "    return image_label_list\n",
    "\n",
    "# Main execution\n",
    "csv_file_path = 'image_labels.csv'  # Replace with your actual CSV file path\n",
    "image_label_dict = read_csv_to_dict(csv_file_path)\n",
    "image_label_list = create_image_label_list(images, image_names, image_label_dict)\n",
    "\n",
    "# Output the result\n",
    "# for item in image_label_list:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2be9842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69161607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('image_labels.csv', names=['image_num','b','c','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad0d64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Misr                        251\n",
       "al-Mansuriyah               223\n",
       "m.                          104\n",
       "al-Mahdiyah                  40\n",
       "(al-Mansuriyah)              10\n",
       "Filastin                      9\n",
       "al-Mansuriyah?                8\n",
       "uncertain                     5\n",
       "(Atarablus)                   4\n",
       "al-Qahirah al-Mahrusah        4\n",
       "Sur                           3\n",
       "Barqa                         3\n",
       "Atarablus                     3\n",
       "Makka                         2\n",
       "Tabariyyah                    2\n",
       "Zawilah                       2\n",
       "(al-Qahirah al-Mahrusah)      1\n",
       "Dimashq                       1\n",
       "Madinat Rasul Allah?          1\n",
       "no mint                       1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c99f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n",
      "al-Mansuriyah\n"
     ]
    }
   ],
   "source": [
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='Misr' or instance[2]=='al-Mansuriyah'or instance[2]=='(al-Mansuriyah)':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "            print(instance[2])\n",
    "        two_largest_list.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca681ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(two_largest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "90315f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5aa7ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 for x in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c686c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 300, 600, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4344d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ratios_one_input(Y):\n",
    "    # Assuming y_train_first is your training labels ndarray\n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "\n",
    "    # Combine the unique labels with their counts\n",
    "    label_counts = dict(zip(unique, counts))\n",
    "\n",
    "    print(label_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eb1a4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ratios_Two_inputs(Y_train,Y_val):\n",
    "    # Assuming y_train_first is your training labels ndarray\n",
    "    unique, counts = np.unique(Y_train, return_counts=True)\n",
    "\n",
    "    # Combine the unique labels with their counts\n",
    "    label_counts_train = dict(zip(unique, counts))\n",
    "\n",
    "    # Print the count of each label\n",
    "    # Assuming y_train_first is your training labels ndarray\n",
    "    unique, counts = np.unique(Y_val, return_counts=True)\n",
    "\n",
    "    # Combine the unique labels with their counts\n",
    "    label_counts_test = dict(zip(unique, counts))\n",
    "    print(\"train\",label_counts_train)\n",
    "    print(\"val\",label_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4e9f85a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 217}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_one_input(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "daa96e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eeefb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 188, 1: 173}\n",
      "val {0: 47, 1: 44}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train_first,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e46ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "057f752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8fae0eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 150, 1: 138}\n",
      "val {0: 38, 1: 35}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a9fa582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "print(y_train)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce0a6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7dfd0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 150, 300, 16)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 75, 150, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81dc7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c73cb456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "9/9 [==============================] - 12s 1s/step - loss: 10.9103 - accuracy: 0.4514 - val_loss: 2.0104 - val_accuracy: 0.4795\n",
      "Epoch 2/18\n",
      "9/9 [==============================] - 10s 1s/step - loss: 1.1580 - accuracy: 0.5035 - val_loss: 0.8927 - val_accuracy: 0.5205\n",
      "Epoch 3/18\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.8033 - accuracy: 0.4931 - val_loss: 0.6656 - val_accuracy: 0.5205\n",
      "Epoch 4/18\n",
      "9/9 [==============================] - 9s 992ms/step - loss: 0.6128 - accuracy: 0.7465 - val_loss: 0.5766 - val_accuracy: 0.8904\n",
      "Epoch 5/18\n",
      "9/9 [==============================] - 8s 940ms/step - loss: 0.4469 - accuracy: 0.8715 - val_loss: 0.4679 - val_accuracy: 0.7945\n",
      "Epoch 6/18\n",
      "9/9 [==============================] - 8s 920ms/step - loss: 0.2950 - accuracy: 0.9271 - val_loss: 0.4623 - val_accuracy: 0.7671\n",
      "Epoch 7/18\n",
      "9/9 [==============================] - 8s 898ms/step - loss: 0.1703 - accuracy: 0.9688 - val_loss: 0.2869 - val_accuracy: 0.9315\n",
      "Epoch 8/18\n",
      "9/9 [==============================] - 9s 998ms/step - loss: 0.1237 - accuracy: 0.9722 - val_loss: 0.2598 - val_accuracy: 0.9315\n",
      "Epoch 9/18\n",
      "9/9 [==============================] - 9s 964ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9452\n",
      "Epoch 10/18\n",
      "9/9 [==============================] - 8s 910ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 11/18\n",
      "9/9 [==============================] - 8s 907ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9452\n",
      "Epoch 12/18\n",
      "9/9 [==============================] - 8s 918ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.2246 - val_accuracy: 0.9178\n",
      "Epoch 13/18\n",
      "9/9 [==============================] - 8s 934ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9178\n",
      "Epoch 14/18\n",
      "9/9 [==============================] - 9s 957ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9452\n",
      "Epoch 15/18\n",
      "9/9 [==============================] - 8s 925ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9452\n",
      "Epoch 16/18\n",
      "9/9 [==============================] - 8s 918ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9452\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f3087437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.28833863139152527 Accuracy: 0.9340659379959106\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d458c70",
   "metadata": {},
   "source": [
    "al-Mahdiyah = 37 , m. = 91 , Misr = 235 , al-Mansuriyah = 217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1f1fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='Misr' or instance[2]=='al-Mansuriyah' or instance[2]=='(al-Mansuriyah)' or instance[2]=='m.':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "            print(instance[2])\n",
    "        three_largest_list.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b8efc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(three_largest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a2b7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in three_largest_list])\n",
    "Y = [row[2] for row in three_largest_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89a0a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    rotation_range = 25,\n",
    "                                    width_shift_range = 0.1,\n",
    "                                    height_shift_range = 0.1,\n",
    "                                    horizontal_flip = True,\n",
    "                                    validation_split = 0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0ef2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c93045e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 if x == 'al-Mansuriyah' else 2 for x in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3eaa1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4efb6adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 217, 2: 91}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_one_input(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0de95f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a561296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 188, 1: 173, 2: 73}\n",
      "val {0: 47, 1: 44, 2: 18}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "784fc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3309e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_val, y_train_2, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=42,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e28972d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 150, 1: 138, 2: 59}\n",
      "val {0: 38, 1: 35, 2: 14}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train_2,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "920e96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2 = to_categorical(y_train_2, num_classes=3)\n",
    "y_val = to_categorical(y_val, num_classes=3)\n",
    "print(y_train_2)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a2eb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ae16540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085603 (175.80 MB)\n",
      "Trainable params: 46085603 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer for 3 classes\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4465f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7dd3eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "11/11 [==============================] - 14s 1s/step - loss: 26.1985 - accuracy: 0.4121 - val_loss: 3.0150 - val_accuracy: 0.1609\n",
      "Epoch 2/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 1.6203 - accuracy: 0.3948 - val_loss: 1.0177 - val_accuracy: 0.5287\n",
      "Epoch 3/18\n",
      "11/11 [==============================] - 11s 969ms/step - loss: 1.0555 - accuracy: 0.5418 - val_loss: 1.0411 - val_accuracy: 0.5747\n",
      "Epoch 4/18\n",
      "11/11 [==============================] - 11s 962ms/step - loss: 0.9670 - accuracy: 0.5965 - val_loss: 0.8285 - val_accuracy: 0.6897\n",
      "Epoch 5/18\n",
      "11/11 [==============================] - 10s 930ms/step - loss: 0.6530 - accuracy: 0.7493 - val_loss: 0.8456 - val_accuracy: 0.7011\n",
      "Epoch 6/18\n",
      "11/11 [==============================] - 10s 955ms/step - loss: 0.3538 - accuracy: 0.8934 - val_loss: 0.6479 - val_accuracy: 0.8046\n",
      "Epoch 7/18\n",
      "11/11 [==============================] - 10s 936ms/step - loss: 0.2011 - accuracy: 0.9481 - val_loss: 0.6626 - val_accuracy: 0.7586\n",
      "Epoch 8/18\n",
      "11/11 [==============================] - 10s 923ms/step - loss: 0.0791 - accuracy: 0.9856 - val_loss: 0.8537 - val_accuracy: 0.7931\n",
      "Epoch 9/18\n",
      "11/11 [==============================] - 11s 979ms/step - loss: 0.0485 - accuracy: 0.9856 - val_loss: 0.6804 - val_accuracy: 0.7471\n",
      "Epoch 10/18\n",
      "11/11 [==============================] - 10s 939ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.7356\n",
      "Epoch 11/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.7471\n",
      "Epoch 12/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.7931\n",
      "Epoch 13/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.7241\n",
      "Epoch 14/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.7241\n",
      "Epoch 15/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2705 - val_accuracy: 0.7701\n",
      "Epoch 16/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1330 - val_accuracy: 0.7931\n",
      "Epoch 17/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.7471\n",
      "Epoch 18/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.8046\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "     X_train_2, y_train_2,\n",
    "#     datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=18,  # Increase the number of epochs to allow for more training\n",
    "    validation_data=(X_val, y_val)\n",
    "#     callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f9ca462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8091941475868225 Accuracy: 0.7431192398071289\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743702a",
   "metadata": {},
   "source": [
    "    We want to improve our accuracy.\n",
    "    I order to do that we will try to find why our model is having difficulties by checking how well it does between all types of coins in pairs\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6b074b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of m. and al-Mansuriyah\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='m.' or instance[2]=='al-Mansuriyah'or instance[2]=='(al-Mansuriyah)':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "        two_largest_list.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "079942f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(two_largest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7194191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c4813565",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'm.' else 1 for x in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d4be195d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 91, 1: 217}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_one_input(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "918aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3e99afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 73, 1: 173}\n",
      "val {0: 18, 1: 44}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train_first,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d9501768",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4e59397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "22999326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 58, 1: 138}\n",
      "val {0: 15, 1: 35}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e033211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "print(y_train)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "55c0896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dbe12548",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "efbc67a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3d07f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "7/7 [==============================] - 10s 1s/step - loss: 22.9564 - accuracy: 0.6224 - val_loss: 5.8904 - val_accuracy: 0.7000\n",
      "Epoch 2/18\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.6090 - accuracy: 0.6224 - val_loss: 1.5570 - val_accuracy: 0.7000\n",
      "Epoch 3/18\n",
      "7/7 [==============================] - 6s 919ms/step - loss: 0.9939 - accuracy: 0.6735 - val_loss: 0.7001 - val_accuracy: 0.4000\n",
      "Epoch 4/18\n",
      "7/7 [==============================] - 6s 914ms/step - loss: 0.6403 - accuracy: 0.7194 - val_loss: 0.6234 - val_accuracy: 0.7000\n",
      "Epoch 5/18\n",
      "7/7 [==============================] - 7s 933ms/step - loss: 0.5848 - accuracy: 0.7041 - val_loss: 0.6277 - val_accuracy: 0.7000\n",
      "Epoch 6/18\n",
      "7/7 [==============================] - 6s 840ms/step - loss: 0.5869 - accuracy: 0.7194 - val_loss: 0.6005 - val_accuracy: 0.6800\n",
      "Epoch 7/18\n",
      "7/7 [==============================] - 6s 840ms/step - loss: 0.5233 - accuracy: 0.7704 - val_loss: 0.6044 - val_accuracy: 0.6800\n",
      "Epoch 8/18\n",
      "7/7 [==============================] - 6s 811ms/step - loss: 0.4661 - accuracy: 0.8214 - val_loss: 0.5937 - val_accuracy: 0.7000\n",
      "Epoch 9/18\n",
      "7/7 [==============================] - 6s 814ms/step - loss: 0.3599 - accuracy: 0.8673 - val_loss: 0.5354 - val_accuracy: 0.7000\n",
      "Epoch 10/18\n",
      "7/7 [==============================] - 6s 883ms/step - loss: 0.2488 - accuracy: 0.9082 - val_loss: 0.6245 - val_accuracy: 0.7000\n",
      "Epoch 11/18\n",
      "7/7 [==============================] - 6s 832ms/step - loss: 0.1768 - accuracy: 0.9592 - val_loss: 0.6242 - val_accuracy: 0.6000\n",
      "Epoch 12/18\n",
      "7/7 [==============================] - 6s 794ms/step - loss: 0.1231 - accuracy: 0.9643 - val_loss: 0.5584 - val_accuracy: 0.7600\n",
      "Epoch 13/18\n",
      "7/7 [==============================] - 6s 826ms/step - loss: 0.0689 - accuracy: 0.9949 - val_loss: 0.5400 - val_accuracy: 0.7400\n",
      "Epoch 14/18\n",
      "7/7 [==============================] - 6s 785ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.7400\n",
      "Epoch 15/18\n",
      "7/7 [==============================] - 6s 784ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.5702 - val_accuracy: 0.7400\n",
      "Epoch 16/18\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.9156 - val_accuracy: 0.7000\n",
      "Epoch 17/18\n",
      "7/7 [==============================] - 6s 842ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7400\n",
      "Epoch 18/18\n",
      "7/7 [==============================] - 6s 804ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 1.0827 - val_accuracy: 0.6800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    "#     callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "71628e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3793977499008179 Accuracy: 0.6774193644523621\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bc446258",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 91, 1: 235}\n",
      "train {0: 73, 1: 187}\n",
      "val {0: 18, 1: 48}\n",
      "train {0: 58, 1: 150}\n",
      "val {0: 15, 1: 37}\n"
     ]
    }
   ],
   "source": [
    "# make a list of m. and Misr\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='m.' or instance[2]=='Misr':\n",
    "        two_largest_list.append(instance)\n",
    "\n",
    "len(two_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'm.' else 1 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ecd18598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.6419 - accuracy: 0.6490 - val_loss: 5.5300 - val_accuracy: 0.7115\n",
      "Epoch 2/18\n",
      "7/7 [==============================] - 6s 890ms/step - loss: 2.0313 - accuracy: 0.5962 - val_loss: 0.6475 - val_accuracy: 0.7115\n",
      "Epoch 3/18\n",
      "7/7 [==============================] - 6s 886ms/step - loss: 0.4543 - accuracy: 0.7644 - val_loss: 0.4241 - val_accuracy: 0.8462\n",
      "Epoch 4/18\n",
      "7/7 [==============================] - 6s 855ms/step - loss: 0.2584 - accuracy: 0.9231 - val_loss: 0.5126 - val_accuracy: 0.7692\n",
      "Epoch 5/18\n",
      "7/7 [==============================] - 6s 824ms/step - loss: 0.0889 - accuracy: 0.9760 - val_loss: 0.2562 - val_accuracy: 0.8846\n",
      "Epoch 6/18\n",
      "7/7 [==============================] - 6s 817ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.8654\n",
      "Epoch 7/18\n",
      "7/7 [==============================] - 6s 822ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9038\n",
      "Epoch 8/18\n",
      "7/7 [==============================] - 6s 836ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.8654\n",
      "Epoch 9/18\n",
      "7/7 [==============================] - 7s 941ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8654\n",
      "Epoch 10/18\n",
      "7/7 [==============================] - 6s 821ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.8846\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "04283edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17107048630714417 Accuracy: 0.939393937587738\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3ce19c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 37}\n",
      "train {0: 187, 1: 30}\n",
      "val {0: 48, 1: 7}\n",
      "train {0: 149, 1: 24}\n",
      "val {0: 38, 1: 6}\n"
     ]
    }
   ],
   "source": [
    "# make a list of al-Mahdiyah  and Misr\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='al-Mahdiyah' or instance[2]=='Misr':\n",
    "        two_largest_list.append(instance)\n",
    "\n",
    "len(two_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ff07cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "6/6 [==============================] - 9s 1s/step - loss: 9.2930 - accuracy: 0.7861 - val_loss: 0.4420 - val_accuracy: 0.8636\n",
      "Epoch 2/18\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.2701 - accuracy: 0.7052 - val_loss: 0.6877 - val_accuracy: 0.8636\n",
      "Epoch 3/18\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.4541 - accuracy: 0.8671 - val_loss: 0.5575 - val_accuracy: 0.8636\n",
      "Epoch 4/18\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 0.2767 - accuracy: 0.9017 - val_loss: 0.4220 - val_accuracy: 0.8636\n",
      "Epoch 5/18\n",
      "6/6 [==============================] - 5s 906ms/step - loss: 0.0960 - accuracy: 0.9711 - val_loss: 0.5443 - val_accuracy: 0.8636\n",
      "Epoch 6/18\n",
      "6/6 [==============================] - 6s 928ms/step - loss: 0.0508 - accuracy: 0.9884 - val_loss: 0.4173 - val_accuracy: 0.8864\n",
      "Epoch 7/18\n",
      "6/6 [==============================] - 5s 877ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.9132 - val_accuracy: 0.8636\n",
      "Epoch 8/18\n",
      "6/6 [==============================] - 5s 913ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.8864\n",
      "Epoch 9/18\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 6.\n",
      "6/6 [==============================] - 5s 898ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8636\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fb4bc384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.31666919589042664 Accuracy: 0.8545454740524292\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "59ccffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 37, 1: 217}\n",
      "train {0: 30, 1: 173}\n",
      "val {0: 7, 1: 44}\n",
      "train {0: 24, 1: 138}\n",
      "val {0: 6, 1: 35}\n"
     ]
    }
   ],
   "source": [
    "# make a list of al-Mahdiyah  and al-Mansuriyah\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='al-Mahdiyah' or instance[2]=='al-Mansuriyah'or instance[2]=='(al-Mansuriyah)':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "        two_largest_list.append(instance)\n",
    "\n",
    "len(two_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'al-Mahdiyah' else 1 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1508eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.8878 - accuracy: 0.6914 - val_loss: 1.7401 - val_accuracy: 0.8537\n",
      "Epoch 2/18\n",
      "6/6 [==============================] - 6s 963ms/step - loss: 1.3019 - accuracy: 0.5864 - val_loss: 0.5741 - val_accuracy: 0.8537\n",
      "Epoch 3/18\n",
      "6/6 [==============================] - 6s 926ms/step - loss: 0.5088 - accuracy: 0.8519 - val_loss: 0.4672 - val_accuracy: 0.8537\n",
      "Epoch 4/18\n",
      "6/6 [==============================] - 6s 933ms/step - loss: 0.4422 - accuracy: 0.8519 - val_loss: 0.4427 - val_accuracy: 0.8537\n",
      "Epoch 5/18\n",
      "6/6 [==============================] - 5s 889ms/step - loss: 0.3773 - accuracy: 0.8519 - val_loss: 0.6099 - val_accuracy: 0.8537\n",
      "Epoch 6/18\n",
      "6/6 [==============================] - 5s 902ms/step - loss: 0.4380 - accuracy: 0.8519 - val_loss: 0.4555 - val_accuracy: 0.8537\n",
      "Epoch 7/18\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8580Restoring model weights from the end of the best epoch: 4.\n",
      "6/6 [==============================] - 5s 892ms/step - loss: 0.3415 - accuracy: 0.8580 - val_loss: 0.4549 - val_accuracy: 0.8537\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2eb7ca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.41825732588768005 Accuracy: 0.8627451062202454\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "455533f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 217, 2: 37}\n",
      "train {0: 188, 1: 173, 2: 30}\n",
      "val {0: 47, 1: 44, 2: 7}\n",
      "train {0: 150, 1: 138, 2: 24}\n",
      "val {0: 38, 1: 35, 2: 6}\n"
     ]
    }
   ],
   "source": [
    "# make a list of al-Mahdiyah  and al-Mansuriyah and Misr\n",
    "\n",
    "three_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='al-Mahdiyah' or instance[2]=='al-Mansuriyah' or instance[2]=='(al-Mansuriyah)' or instance[2]=='Misr':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "        three_largest_list.append(instance)\n",
    "\n",
    "len(three_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in three_largest_list])\n",
    "Y = np.array([row[2] for row in three_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 if x == 'al-Mansuriyah' else 2 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_val = to_categorical(y_val, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1a010263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085603 (175.80 MB)\n",
      "Trainable params: 46085603 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "10/10 [==============================] - 18s 1s/step - loss: 11.2347 - accuracy: 0.4295 - val_loss: 1.8094 - val_accuracy: 0.4810\n",
      "Epoch 2/18\n",
      "10/10 [==============================] - 10s 995ms/step - loss: 1.4841 - accuracy: 0.4936 - val_loss: 1.0951 - val_accuracy: 0.4430\n",
      "Epoch 3/18\n",
      "10/10 [==============================] - 10s 962ms/step - loss: 0.8785 - accuracy: 0.5962 - val_loss: 0.7018 - val_accuracy: 0.8354\n",
      "Epoch 4/18\n",
      "10/10 [==============================] - 9s 924ms/step - loss: 0.5948 - accuracy: 0.8333 - val_loss: 0.5809 - val_accuracy: 0.8354\n",
      "Epoch 5/18\n",
      "10/10 [==============================] - 9s 939ms/step - loss: 0.3699 - accuracy: 0.8878 - val_loss: 0.5054 - val_accuracy: 0.8987\n",
      "Epoch 6/18\n",
      "10/10 [==============================] - 9s 892ms/step - loss: 0.1977 - accuracy: 0.9487 - val_loss: 0.5010 - val_accuracy: 0.8354\n",
      "Epoch 7/18\n",
      "10/10 [==============================] - 9s 860ms/step - loss: 0.1046 - accuracy: 0.9712 - val_loss: 0.4577 - val_accuracy: 0.8101\n",
      "Epoch 8/18\n",
      "10/10 [==============================] - 9s 872ms/step - loss: 0.0702 - accuracy: 0.9776 - val_loss: 0.6111 - val_accuracy: 0.8354\n",
      "Epoch 9/18\n",
      "10/10 [==============================] - 9s 891ms/step - loss: 0.0518 - accuracy: 0.9968 - val_loss: 0.6558 - val_accuracy: 0.8228\n",
      "Epoch 10/18\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 7.\n",
      "10/10 [==============================] - 9s 880ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.5987 - val_accuracy: 0.8354\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer for 3 classes\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "83af01a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7337673902511597 Accuracy: 0.7857142686843872\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edaab35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
