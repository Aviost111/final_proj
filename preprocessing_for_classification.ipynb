{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e308fe-d8f4-4e01-aa0e-de6997836209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.applications import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall ,F1Score\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e831beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"Combined_images\"\n",
    "image_list = []\n",
    "file_names = []\n",
    "\n",
    "# Iterate over each file in the specified directory\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(('.jpg', '.png', '.tif', '.JPG')):\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        img = cv2.imread(file_path)\n",
    "        # Append the image and its filename to the lists\n",
    "        image_list.append(img)\n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0d8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the number from the image filename\n",
    "def extract_number_from_filename(filename):\n",
    "    # Assuming the number is after 'combined_' and before the first '.'\n",
    "    return filename.split('_')[1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c50041",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file_names = []\n",
    "for name in file_names:\n",
    "    clean_file_names.append(extract_number_from_filename(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7892d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (replace these with your actual data)\n",
    "images = image_list\n",
    "image_names = clean_file_names\n",
    "\n",
    "# Function to read the CSV and create a dictionary of image names to labels\n",
    "def read_csv_to_dict(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract image names and labels\n",
    "    image_names = df.iloc[:, 0].values\n",
    "    labels = df.iloc[:, -1].values\n",
    "\n",
    "    # Create a list of image-label pairs\n",
    "    image_label_array = np.array([[name, label] for name, label in zip(image_names, labels)])\n",
    "    \n",
    "    # Convert the NumPy array to a dictionary\n",
    "    image_label_dict = {row[0]: row[1] for row in image_label_array}\n",
    "    return image_label_dict\n",
    "\n",
    "\n",
    "# Function to create the list of images and their corresponding labels\n",
    "def create_image_label_list(images, image_names, image_label_dict):\n",
    "    image_label_list = []\n",
    "    for image, name in zip(images, image_names):\n",
    "        if name in image_label_dict:\n",
    "            label = image_label_dict[name]\n",
    "            image_label_list.append([name,image, label])\n",
    "    return image_label_list\n",
    "\n",
    "# Main execution\n",
    "csv_file_path = 'image_labels.csv'  # Replace with your actual CSV file path\n",
    "image_label_dict = read_csv_to_dict(csv_file_path)\n",
    "image_label_list = create_image_label_list(images, image_names, image_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2be9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 625\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of images: {len(image_label_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69161607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('image_labels.csv', names=['image_num','b','c','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad0d64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Misr</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al-Mansuriyah</th>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al-Mahdiyah</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(al-Mansuriyah)</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filastin</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al-Mansuriyah?</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncertain</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Atarablus)</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al-Qahirah al-Mahrusah</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sur</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barqa</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atarablus</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Makka</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabariyyah</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zawilah</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(al-Qahirah al-Mahrusah)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dimashq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madinat Rasul Allah?</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no mint</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count\n",
       "label                          \n",
       "Misr                        251\n",
       "al-Mansuriyah               223\n",
       "m.                          104\n",
       "al-Mahdiyah                  40\n",
       "(al-Mansuriyah)              10\n",
       "Filastin                      9\n",
       "al-Mansuriyah?                8\n",
       "uncertain                     5\n",
       "(Atarablus)                   4\n",
       "al-Qahirah al-Mahrusah        4\n",
       "Sur                           3\n",
       "Barqa                         3\n",
       "Atarablus                     3\n",
       "Makka                         2\n",
       "Tabariyyah                    2\n",
       "Zawilah                       2\n",
       "(al-Qahirah al-Mahrusah)      1\n",
       "Dimashq                       1\n",
       "Madinat Rasul Allah?          1\n",
       "no mint                       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c99f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='Misr' or instance[2]=='al-Mansuriyah'or instance[2]=='(al-Mansuriyah)':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "        two_largest_list.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca681ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 452\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of images: {len(two_largest_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90315f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa7ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 for x in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c686c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 300, 600, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4344d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ratios_one_input(Y):\n",
    "    # Assuming y_train_first is your training labels ndarray\n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "\n",
    "    # Combine the unique labels with their counts\n",
    "    label_counts = dict(zip(unique, counts))\n",
    "\n",
    "    print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb1a4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ratios_Two_inputs(Y_train,Y_val):\n",
    "    # Assuming y_train_first is your training labels ndarray\n",
    "    unique, counts = np.unique(Y_train, return_counts=True)\n",
    "\n",
    "    # Combine the unique labels with their counts\n",
    "    label_counts_train = dict(zip(unique, counts))\n",
    "\n",
    "    # Print the count of each label\n",
    "    # Assuming y_train_first is your training labels ndarray\n",
    "    unique, counts = np.unique(Y_val, return_counts=True)\n",
    "\n",
    "    # Combine the unique labels with their counts\n",
    "    label_counts_test = dict(zip(unique, counts))\n",
    "    print(\"train\",label_counts_train)\n",
    "    print(\"val\",label_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e9f85a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 217}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_one_input(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daa96e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeefb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 188, 1: 173}\n",
      "val {0: 47, 1: 44}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train_first,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e46ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "057f752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fae0eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 150, 1: 138}\n",
      "val {0: 38, 1: 35}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a64ca660",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae81b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce0a6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dfd0f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360000</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">46,080,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360000\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m46,080,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m258\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,085,474</span> (175.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,085,474\u001b[0m (175.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,085,474</span> (175.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,085,474\u001b[0m (175.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81dc7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c73cb456",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.4629 - loss: 20.9588 - val_accuracy: 0.5205 - val_loss: 0.7538\n",
      "Epoch 2/18\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 739ms/step - accuracy: 0.5301 - loss: 1.2465 - val_accuracy: 0.5205 - val_loss: 0.7277\n",
      "Epoch 3/18\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 695ms/step - accuracy: 0.5523 - loss: 0.6917 - val_accuracy: 0.4795 - val_loss: 0.6955\n",
      "Epoch 4/18\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 690ms/step - accuracy: 0.4485 - loss: 0.7101 - val_accuracy: 0.4795 - val_loss: 0.6907\n",
      "Epoch 5/18\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 687ms/step - accuracy: 0.5295 - loss: 0.6950 - val_accuracy: 0.5205 - val_loss: 0.6930\n",
      "Epoch 6/18\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 680ms/step - accuracy: 0.5404 - loss: 0.7034 - val_accuracy: 0.5205 - val_loss: 0.6929\n",
      "Epoch 7/18\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 678ms/step - accuracy: 0.4828 - loss: 0.6985 - val_accuracy: 0.5205 - val_loss: 0.7036\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3087437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3587842583656311 Accuracy: 0.8681318759918213\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fd67fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:547\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m     )\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m     )\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 2)"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(300, 600, 3), padding='same', name='conv2d_4'))\n",
    "model.add(MaxPooling2D((2, 2), name='max_pooling2d_4'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv2d_5'))\n",
    "model.add(MaxPooling2D((2, 2), name='max_pooling2d_5'))\n",
    "model.add(Flatten(name='flatten_2'))\n",
    "model.add(Dense(128, activation='relu', name='dense_4'))\n",
    "model.add(Dropout(0.2, name='dropout_2'))\n",
    "model.add(Dense(2, activation='softmax', name='dense_5'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=18, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Load the model\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "# Make a prediction to build the model layers\n",
    "_ = model.predict(np.expand_dims(X_test[0], axis=0))\n",
    "\n",
    "# Function to compute Grad-CAM\n",
    "def get_gradcam(model, img_array, layer_name):\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, np.argmax(predictions[0])]\n",
    "\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    gate_f = tf.cast(output > 0, 'float32')\n",
    "    gate_r = tf.cast(grads > 0, 'float32')\n",
    "    guided_grads = gate_f * gate_r * grads\n",
    "\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "    cam = np.zeros(output.shape[0:2], dtype=np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "\n",
    "    cam = cv2.resize(cam.numpy(), (img_array.shape[2], img_array.shape[1]))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "# Function to display Grad-CAM\n",
    "def display_gradcam(img, heatmap):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    overlay = heatmap + np.float32(img)\n",
    "    overlay = overlay / np.max(overlay)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(overlay)\n",
    "    plt.show()\n",
    "\n",
    "# Select an image from the test set\n",
    "img = X_test[0]\n",
    "img_array = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Get Grad-CAM heatmap for the last convolutional layer\n",
    "layer_name = 'conv2d_5'  # Use the correct last conv layer name\n",
    "heatmap = get_gradcam(model, img_array, layer_name)\n",
    "\n",
    "# Display Grad-CAM\n",
    "display_gradcam(img, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1f1fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='Misr' or instance[2]=='al-Mansuriyah' or instance[2]=='(al-Mansuriyah)' or instance[2]=='m.':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "            print(instance[2])\n",
    "        three_largest_list.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b8efc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(three_largest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a2b7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in three_largest_list])\n",
    "Y = [row[2] for row in three_largest_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89a0a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    rotation_range = 25,\n",
    "                                    width_shift_range = 0.1,\n",
    "                                    height_shift_range = 0.1,\n",
    "                                    horizontal_flip = True,\n",
    "                                    validation_split = 0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c93045e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 if x == 'al-Mansuriyah' else 2 for x in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3eaa1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4efb6adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 217, 2: 91}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_one_input(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0de95f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a561296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 188, 1: 173, 2: 73}\n",
      "val {0: 47, 1: 44, 2: 18}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "784fc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3309e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_val, y_train_2, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=42,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e28972d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 150, 1: 138, 2: 59}\n",
      "val {0: 38, 1: 35, 2: 14}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train_2,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "920e96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2 = to_categorical(y_train_2, num_classes=3)\n",
    "y_val = to_categorical(y_val, num_classes=3)\n",
    "print(y_train_2)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a2eb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ae16540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085603 (175.80 MB)\n",
      "Trainable params: 46085603 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer for 3 classes\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4465f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7dd3eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "11/11 [==============================] - 14s 1s/step - loss: 26.1985 - accuracy: 0.4121 - val_loss: 3.0150 - val_accuracy: 0.1609\n",
      "Epoch 2/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 1.6203 - accuracy: 0.3948 - val_loss: 1.0177 - val_accuracy: 0.5287\n",
      "Epoch 3/18\n",
      "11/11 [==============================] - 11s 969ms/step - loss: 1.0555 - accuracy: 0.5418 - val_loss: 1.0411 - val_accuracy: 0.5747\n",
      "Epoch 4/18\n",
      "11/11 [==============================] - 11s 962ms/step - loss: 0.9670 - accuracy: 0.5965 - val_loss: 0.8285 - val_accuracy: 0.6897\n",
      "Epoch 5/18\n",
      "11/11 [==============================] - 10s 930ms/step - loss: 0.6530 - accuracy: 0.7493 - val_loss: 0.8456 - val_accuracy: 0.7011\n",
      "Epoch 6/18\n",
      "11/11 [==============================] - 10s 955ms/step - loss: 0.3538 - accuracy: 0.8934 - val_loss: 0.6479 - val_accuracy: 0.8046\n",
      "Epoch 7/18\n",
      "11/11 [==============================] - 10s 936ms/step - loss: 0.2011 - accuracy: 0.9481 - val_loss: 0.6626 - val_accuracy: 0.7586\n",
      "Epoch 8/18\n",
      "11/11 [==============================] - 10s 923ms/step - loss: 0.0791 - accuracy: 0.9856 - val_loss: 0.8537 - val_accuracy: 0.7931\n",
      "Epoch 9/18\n",
      "11/11 [==============================] - 11s 979ms/step - loss: 0.0485 - accuracy: 0.9856 - val_loss: 0.6804 - val_accuracy: 0.7471\n",
      "Epoch 10/18\n",
      "11/11 [==============================] - 10s 939ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.7356\n",
      "Epoch 11/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.7471\n",
      "Epoch 12/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.7931\n",
      "Epoch 13/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.7241\n",
      "Epoch 14/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.7241\n",
      "Epoch 15/18\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2705 - val_accuracy: 0.7701\n",
      "Epoch 16/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1330 - val_accuracy: 0.7931\n",
      "Epoch 17/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.7471\n",
      "Epoch 18/18\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.8046\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "     X_train_2, y_train_2,\n",
    "#     datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=18,  # Increase the number of epochs to allow for more training\n",
    "    validation_data=(X_val, y_val)\n",
    "#     callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f9ca462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8091941475868225 Accuracy: 0.7431192398071289\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743702a",
   "metadata": {},
   "source": [
    "    We want to improve our accuracy.\n",
    "    I order to do that we will try to find why our model is having difficulties by checking how well it does between all types of coins in pairs\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6b074b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of m. and al-Mansuriyah\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='m.' or instance[2]=='al-Mansuriyah'or instance[2]=='(al-Mansuriyah)':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "        two_largest_list.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "079942f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(two_largest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7194191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c4813565",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'm.' else 1 for x in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d4be195d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 91, 1: 217}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_one_input(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "918aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3e99afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 73, 1: 173}\n",
      "val {0: 18, 1: 44}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train_first,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d9501768",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4e59397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "22999326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {0: 58, 1: 138}\n",
      "val {0: 15, 1: 35}\n"
     ]
    }
   ],
   "source": [
    "print_ratios_Two_inputs(y_train,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e033211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "print(y_train)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "55c0896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dbe12548",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "efbc67a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3d07f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "7/7 [==============================] - 10s 1s/step - loss: 22.9564 - accuracy: 0.6224 - val_loss: 5.8904 - val_accuracy: 0.7000\n",
      "Epoch 2/18\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.6090 - accuracy: 0.6224 - val_loss: 1.5570 - val_accuracy: 0.7000\n",
      "Epoch 3/18\n",
      "7/7 [==============================] - 6s 919ms/step - loss: 0.9939 - accuracy: 0.6735 - val_loss: 0.7001 - val_accuracy: 0.4000\n",
      "Epoch 4/18\n",
      "7/7 [==============================] - 6s 914ms/step - loss: 0.6403 - accuracy: 0.7194 - val_loss: 0.6234 - val_accuracy: 0.7000\n",
      "Epoch 5/18\n",
      "7/7 [==============================] - 7s 933ms/step - loss: 0.5848 - accuracy: 0.7041 - val_loss: 0.6277 - val_accuracy: 0.7000\n",
      "Epoch 6/18\n",
      "7/7 [==============================] - 6s 840ms/step - loss: 0.5869 - accuracy: 0.7194 - val_loss: 0.6005 - val_accuracy: 0.6800\n",
      "Epoch 7/18\n",
      "7/7 [==============================] - 6s 840ms/step - loss: 0.5233 - accuracy: 0.7704 - val_loss: 0.6044 - val_accuracy: 0.6800\n",
      "Epoch 8/18\n",
      "7/7 [==============================] - 6s 811ms/step - loss: 0.4661 - accuracy: 0.8214 - val_loss: 0.5937 - val_accuracy: 0.7000\n",
      "Epoch 9/18\n",
      "7/7 [==============================] - 6s 814ms/step - loss: 0.3599 - accuracy: 0.8673 - val_loss: 0.5354 - val_accuracy: 0.7000\n",
      "Epoch 10/18\n",
      "7/7 [==============================] - 6s 883ms/step - loss: 0.2488 - accuracy: 0.9082 - val_loss: 0.6245 - val_accuracy: 0.7000\n",
      "Epoch 11/18\n",
      "7/7 [==============================] - 6s 832ms/step - loss: 0.1768 - accuracy: 0.9592 - val_loss: 0.6242 - val_accuracy: 0.6000\n",
      "Epoch 12/18\n",
      "7/7 [==============================] - 6s 794ms/step - loss: 0.1231 - accuracy: 0.9643 - val_loss: 0.5584 - val_accuracy: 0.7600\n",
      "Epoch 13/18\n",
      "7/7 [==============================] - 6s 826ms/step - loss: 0.0689 - accuracy: 0.9949 - val_loss: 0.5400 - val_accuracy: 0.7400\n",
      "Epoch 14/18\n",
      "7/7 [==============================] - 6s 785ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.7400\n",
      "Epoch 15/18\n",
      "7/7 [==============================] - 6s 784ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.5702 - val_accuracy: 0.7400\n",
      "Epoch 16/18\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.9156 - val_accuracy: 0.7000\n",
      "Epoch 17/18\n",
      "7/7 [==============================] - 6s 842ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7400\n",
      "Epoch 18/18\n",
      "7/7 [==============================] - 6s 804ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 1.0827 - val_accuracy: 0.6800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    "#     callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "71628e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3793977499008179 Accuracy: 0.6774193644523621\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bc446258",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 91, 1: 235}\n",
      "train {0: 73, 1: 187}\n",
      "val {0: 18, 1: 48}\n",
      "train {0: 58, 1: 150}\n",
      "val {0: 15, 1: 37}\n"
     ]
    }
   ],
   "source": [
    "# make a list of m. and Misr\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='m.' or instance[2]=='Misr':\n",
    "        two_largest_list.append(instance)\n",
    "\n",
    "len(two_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'm.' else 1 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ecd18598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.6419 - accuracy: 0.6490 - val_loss: 5.5300 - val_accuracy: 0.7115\n",
      "Epoch 2/18\n",
      "7/7 [==============================] - 6s 890ms/step - loss: 2.0313 - accuracy: 0.5962 - val_loss: 0.6475 - val_accuracy: 0.7115\n",
      "Epoch 3/18\n",
      "7/7 [==============================] - 6s 886ms/step - loss: 0.4543 - accuracy: 0.7644 - val_loss: 0.4241 - val_accuracy: 0.8462\n",
      "Epoch 4/18\n",
      "7/7 [==============================] - 6s 855ms/step - loss: 0.2584 - accuracy: 0.9231 - val_loss: 0.5126 - val_accuracy: 0.7692\n",
      "Epoch 5/18\n",
      "7/7 [==============================] - 6s 824ms/step - loss: 0.0889 - accuracy: 0.9760 - val_loss: 0.2562 - val_accuracy: 0.8846\n",
      "Epoch 6/18\n",
      "7/7 [==============================] - 6s 817ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.8654\n",
      "Epoch 7/18\n",
      "7/7 [==============================] - 6s 822ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9038\n",
      "Epoch 8/18\n",
      "7/7 [==============================] - 6s 836ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.8654\n",
      "Epoch 9/18\n",
      "7/7 [==============================] - 7s 941ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8654\n",
      "Epoch 10/18\n",
      "7/7 [==============================] - 6s 821ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.8846\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "04283edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17107048630714417 Accuracy: 0.939393937587738\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3ce19c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 37}\n",
      "train {0: 187, 1: 30}\n",
      "val {0: 48, 1: 7}\n",
      "train {0: 149, 1: 24}\n",
      "val {0: 38, 1: 6}\n"
     ]
    }
   ],
   "source": [
    "# make a list of al-Mahdiyah  and Misr\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='al-Mahdiyah' or instance[2]=='Misr':\n",
    "        two_largest_list.append(instance)\n",
    "\n",
    "len(two_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ff07cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "6/6 [==============================] - 9s 1s/step - loss: 9.2930 - accuracy: 0.7861 - val_loss: 0.4420 - val_accuracy: 0.8636\n",
      "Epoch 2/18\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.2701 - accuracy: 0.7052 - val_loss: 0.6877 - val_accuracy: 0.8636\n",
      "Epoch 3/18\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.4541 - accuracy: 0.8671 - val_loss: 0.5575 - val_accuracy: 0.8636\n",
      "Epoch 4/18\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 0.2767 - accuracy: 0.9017 - val_loss: 0.4220 - val_accuracy: 0.8636\n",
      "Epoch 5/18\n",
      "6/6 [==============================] - 5s 906ms/step - loss: 0.0960 - accuracy: 0.9711 - val_loss: 0.5443 - val_accuracy: 0.8636\n",
      "Epoch 6/18\n",
      "6/6 [==============================] - 6s 928ms/step - loss: 0.0508 - accuracy: 0.9884 - val_loss: 0.4173 - val_accuracy: 0.8864\n",
      "Epoch 7/18\n",
      "6/6 [==============================] - 5s 877ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.9132 - val_accuracy: 0.8636\n",
      "Epoch 8/18\n",
      "6/6 [==============================] - 5s 913ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.8864\n",
      "Epoch 9/18\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 6.\n",
      "6/6 [==============================] - 5s 898ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8636\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fb4bc384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.31666919589042664 Accuracy: 0.8545454740524292\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "59ccffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 37, 1: 217}\n",
      "train {0: 30, 1: 173}\n",
      "val {0: 7, 1: 44}\n",
      "train {0: 24, 1: 138}\n",
      "val {0: 6, 1: 35}\n"
     ]
    }
   ],
   "source": [
    "# make a list of al-Mahdiyah  and al-Mansuriyah\n",
    "\n",
    "two_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='al-Mahdiyah' or instance[2]=='al-Mansuriyah'or instance[2]=='(al-Mansuriyah)':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "        two_largest_list.append(instance)\n",
    "\n",
    "len(two_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in two_largest_list])\n",
    "Y = np.array([row[2] for row in two_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'al-Mahdiyah' else 1 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1508eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085474 (175.80 MB)\n",
      "Trainable params: 46085474 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "6/6 [==============================] - 8s 1s/step - loss: 5.8878 - accuracy: 0.6914 - val_loss: 1.7401 - val_accuracy: 0.8537\n",
      "Epoch 2/18\n",
      "6/6 [==============================] - 6s 963ms/step - loss: 1.3019 - accuracy: 0.5864 - val_loss: 0.5741 - val_accuracy: 0.8537\n",
      "Epoch 3/18\n",
      "6/6 [==============================] - 6s 926ms/step - loss: 0.5088 - accuracy: 0.8519 - val_loss: 0.4672 - val_accuracy: 0.8537\n",
      "Epoch 4/18\n",
      "6/6 [==============================] - 6s 933ms/step - loss: 0.4422 - accuracy: 0.8519 - val_loss: 0.4427 - val_accuracy: 0.8537\n",
      "Epoch 5/18\n",
      "6/6 [==============================] - 5s 889ms/step - loss: 0.3773 - accuracy: 0.8519 - val_loss: 0.6099 - val_accuracy: 0.8537\n",
      "Epoch 6/18\n",
      "6/6 [==============================] - 5s 902ms/step - loss: 0.4380 - accuracy: 0.8519 - val_loss: 0.4555 - val_accuracy: 0.8537\n",
      "Epoch 7/18\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8580Restoring model weights from the end of the best epoch: 4.\n",
      "6/6 [==============================] - 5s 892ms/step - loss: 0.3415 - accuracy: 0.8580 - val_loss: 0.4549 - val_accuracy: 0.8537\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2eb7ca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.41825732588768005 Accuracy: 0.8627451062202454\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "455533f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 235, 1: 217, 2: 37}\n",
      "train {0: 188, 1: 173, 2: 30}\n",
      "val {0: 47, 1: 44, 2: 7}\n",
      "train {0: 150, 1: 138, 2: 24}\n",
      "val {0: 38, 1: 35, 2: 6}\n"
     ]
    }
   ],
   "source": [
    "# make a list of al-Mahdiyah  and al-Mansuriyah and Misr\n",
    "\n",
    "three_largest_list = []\n",
    "for instance in image_label_list:\n",
    "    if instance[2]=='al-Mahdiyah' or instance[2]=='al-Mansuriyah' or instance[2]=='(al-Mansuriyah)' or instance[2]=='Misr':\n",
    "        if instance[2]=='(al-Mansuriyah)':\n",
    "            instance[2]='al-Mansuriyah'\n",
    "        three_largest_list.append(instance)\n",
    "\n",
    "len(three_largest_list)\n",
    "\n",
    "# Convert resized_image_list to numpy array\n",
    "X = np.array([row[1] for row in three_largest_list])\n",
    "Y = np.array([row[2] for row in three_largest_list])\n",
    "\n",
    "X = X/255.0\n",
    "Y = np.array([0 if x == 'Misr' else 1 if x == 'al-Mansuriyah' else 2 for x in Y])\n",
    "\n",
    "print_ratios_one_input(Y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train_first, X_test, y_train_first, y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "print_ratios_Two_inputs(y_train_first,y_test)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_first,y_train_first, test_size=0.2, random_state=42, stratify=y_train_first)\n",
    "\n",
    "print_ratios_Two_inputs(y_train,y_val)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_val = to_categorical(y_val, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1a010263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 300, 600, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPooli  (None, 150, 300, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 150, 300, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPooli  (None, 75, 150, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 360000)            0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               46080128  \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46085603 (175.80 MB)\n",
      "Trainable params: 46085603 (175.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "10/10 [==============================] - 18s 1s/step - loss: 11.2347 - accuracy: 0.4295 - val_loss: 1.8094 - val_accuracy: 0.4810\n",
      "Epoch 2/18\n",
      "10/10 [==============================] - 10s 995ms/step - loss: 1.4841 - accuracy: 0.4936 - val_loss: 1.0951 - val_accuracy: 0.4430\n",
      "Epoch 3/18\n",
      "10/10 [==============================] - 10s 962ms/step - loss: 0.8785 - accuracy: 0.5962 - val_loss: 0.7018 - val_accuracy: 0.8354\n",
      "Epoch 4/18\n",
      "10/10 [==============================] - 9s 924ms/step - loss: 0.5948 - accuracy: 0.8333 - val_loss: 0.5809 - val_accuracy: 0.8354\n",
      "Epoch 5/18\n",
      "10/10 [==============================] - 9s 939ms/step - loss: 0.3699 - accuracy: 0.8878 - val_loss: 0.5054 - val_accuracy: 0.8987\n",
      "Epoch 6/18\n",
      "10/10 [==============================] - 9s 892ms/step - loss: 0.1977 - accuracy: 0.9487 - val_loss: 0.5010 - val_accuracy: 0.8354\n",
      "Epoch 7/18\n",
      "10/10 [==============================] - 9s 860ms/step - loss: 0.1046 - accuracy: 0.9712 - val_loss: 0.4577 - val_accuracy: 0.8101\n",
      "Epoch 8/18\n",
      "10/10 [==============================] - 9s 872ms/step - loss: 0.0702 - accuracy: 0.9776 - val_loss: 0.6111 - val_accuracy: 0.8354\n",
      "Epoch 9/18\n",
      "10/10 [==============================] - 9s 891ms/step - loss: 0.0518 - accuracy: 0.9968 - val_loss: 0.6558 - val_accuracy: 0.8228\n",
      "Epoch 10/18\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 7.\n",
      "10/10 [==============================] - 9s 880ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.5987 - val_accuracy: 0.8354\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu', input_shape=(300, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with fewer filters\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with fewer neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer for 3 classes\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=18,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "83af01a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7337673902511597 Accuracy: 0.7857142686843872\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edaab35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
