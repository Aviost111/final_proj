{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, we aim to evaluate the performance and consistency of our pre-trained coin classification model on the third largest class in our dataset. The model was originally trained on the two largest classes. By testing the third class, we seek to understand whether it shares similarities with the classes the model was trained on and if the model can accurately classify images from this third class.\n",
    "\n",
    "**Key Objectives**:\n",
    "1. **Load the Pre-trained Model**: We will load the model that was trained on the two largest classes to ensure consistency in our evaluation.\n",
    "2. **Prepare the Third Class Dataset**: Images from the third largest class will be loaded and preprocessed to match the format used in the original training.\n",
    "3. **Evaluate Model Performance**: The pre-trained model will be tested on the third class dataset to assess its performance.\n",
    "4. **Analyze Consistency**: We will analyze the consistency of the model's classification results on the third class to determine if the model can generalize its learned features to this new class.\n",
    "\n",
    "By the end of this notebook, we will gain insights into the model's ability to handle unseen classes and its potential for generalization beyond the initial training set. This analysis will help us understand the model's strengths and limitations, guiding future improvements and training strategies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils import normalize\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing the model on `al-Mahdiyah` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 'al-Mahdiyah'\n",
    "\n",
    "data_path = r\"Combined_images\"\n",
    "\n",
    "file_names = []\n",
    "\n",
    "# Iterate over each file in the specified directory\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(('.jpg', '.png', '.tif', '.JPG')):\n",
    "        file_names.append(filename)\n",
    "\n",
    "# Function to extract the number from the image filename\n",
    "def extract_number_from_filename(filename):\n",
    "    return filename.split('_')[1].split('.')[0]\n",
    "\n",
    "image_names = []\n",
    "\n",
    "for name in file_names:\n",
    "    image_names.append(extract_number_from_filename(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the CSV and create a dictionary of image names to labels\n",
    "def read_csv_to_dict(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract image names and labels\n",
    "    image_names = df.iloc[:, 0].values\n",
    "    labels = df.iloc[:, -1].values\n",
    "\n",
    "    # Create a list of image-label pairs\n",
    "    image_label_array = np.array([[name, label] for name, label in zip(image_names, labels)])\n",
    "    \n",
    "    # Convert the NumPy array to a dictionary\n",
    "    image_label_dict = {row[0]: row[1] for row in image_label_array}\n",
    "    return image_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "csv_file_path = 'image_labels.csv'\n",
    "image_label_dict = read_csv_to_dict(csv_file_path)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(file_path):\n",
    "    img = load_img(file_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for image files and load images and labels\n",
    "images = []\n",
    "for key, label in image_label_dict.items():\n",
    "    found = False\n",
    "    for root, _, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            if key in file and label == class_label:\n",
    "                file_path = os.path.join(root, file)\n",
    "                img_array = load_and_preprocess_image(file_path)\n",
    "                images.append(img_array)\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "# Convert to numpy arrays\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model('fine_tuned_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 563ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the images using the model\n",
    "predictions = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(predictions, axis=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that except for 3 images, all the images are classified as class 1.\n",
    "# This can help us infer that maybe'al-mahdiyah' class is similar to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
