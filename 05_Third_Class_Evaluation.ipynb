{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, we aim to evaluate the performance and consistency of our pre-trained coin classification model on the third largest class in our dataset. The model was originally trained on the two largest classes. By testing the third class, we seek to understand whether it shares similarities with the classes the model was trained on and if the model can accurately classify images from this third class.\n",
    "\n",
    "**Key Objectives**:\n",
    "1. **Load the Pre-trained Model**: We will load the model that was trained on the two largest classes to ensure consistency in our evaluation.\n",
    "2. **Prepare the Third Class Dataset**: Images from the third largest class will be loaded and preprocessed to match the format used in the original training.\n",
    "3. **Evaluate Model Performance**: The pre-trained model will be tested on the third class dataset to assess its performance.\n",
    "4. **Analyze Consistency**: We will analyze the consistency of the model's classification results on the third class to determine if the model can generalize its learned features to this new class.\n",
    "\n",
    "By the end of this notebook, we will gain insights into the model's ability to handle unseen classes and its potential for generalization beyond the initial training set. This analysis will help us understand the model's strengths and limitations, guiding future improvements and training strategies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils import normalize\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing the model on `al-Mahdiyah` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 'al-Mahdiyah'\n",
    "csv_file_path = 'image_labels.csv'\n",
    "data_path = \"Combined_images\"\n",
    "\n",
    "file_names = []\n",
    "\n",
    "# Iterate over each file in the specified directory\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(('.jpg', '.png', '.tif', '.JPG')):\n",
    "        file_names.append(filename)\n",
    "\n",
    "# Function to extract the number from the image filename\n",
    "def extract_number_from_filename(filename):\n",
    "    return filename.split('_')[1].split('.')[0]\n",
    "\n",
    "image_names = []\n",
    "\n",
    "for name in file_names:\n",
    "    image_names.append(extract_number_from_filename(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the CSV and create a dictionary of image names to labels\n",
    "def read_csv_to_dict(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract image names and labels\n",
    "    image_names = df.iloc[:, 0].values\n",
    "    labels = df.iloc[:, -1].values\n",
    "\n",
    "    # Create a list of image-label pairs\n",
    "    image_label_array = np.array([[name, label] for name, label in zip(image_names, labels)])\n",
    "    \n",
    "    # Convert the NumPy array to a dictionary\n",
    "    image_label_dict = {row[0]: row[1] for row in image_label_array}\n",
    "    return image_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label_dict = read_csv_to_dict(csv_file_path)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(file_path):\n",
    "    img = load_img(file_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for image files and load images and labels\n",
    "images = []\n",
    "image_labels = []\n",
    "for key, label in image_label_dict.items():\n",
    "    found = False\n",
    "    for root, _, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            if key in file and label == class_label:\n",
    "                file_path = os.path.join(root, file)\n",
    "                img_array = load_and_preprocess_image(file_path)\n",
    "                images.append(img_array)\n",
    "                image_labels.append(label)\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "# Convert to numpy arrays\n",
    "images = np.array(images)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "# Encode labels as integers\n",
    "label_to_index = {label: idx for idx, label in enumerate(np.unique(image_labels))}\n",
    "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "image_labels = np.array([label_to_index[label] for label in image_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pre-trained Model\n",
    "\n",
    "In this section, we will load the pre-trained model that was trained on the two largest classes.   \n",
    "This will allow us to evaluate its performance on the third largest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the model with the same architecture as the pre-trained model\n",
    "def create_model(num_classes):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Add custom top layers for transfer learning\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Combine base model and new top layers\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze the layers of the base model (not trainable)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the model with the same architecture as the previous one\n",
    "num_classes = 2  # Change to the number of classes in your pre-trained model\n",
    "model = create_model(num_classes)\n",
    "model.load_weights('fine_tuned_vgg16.h5')\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model Performance on the Third Class\n",
    "In this section, we will evaluate the model's performance on the third largest class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step\n",
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_images = preprocess_input(images)\n",
    "\n",
    "predictions = model.predict(preprocessed_images)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: Misr\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: Misr\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: Misr\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n",
      "True class: al-Mahdiyah, Predicted class: al-Mansuriyah\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "classes = ['Misr', 'al-Mansuriyah']\n",
    "\n",
    "for i, img_array in enumerate(preprocessed_images):\n",
    "    true_class = image_labels[i]\n",
    "    print(f\"True class: {index_to_label[true_class]}\" ,end=', ')\n",
    "    print(f\"Predicted class: {classes[predicted_class[i]]}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Conclusion\n",
    "We can see that except for 3 images, all the images are classified as 'al-Mansuriyah'.\n",
    "This can help us infer that the 'al-Mahdiyah' class might be similar to class 1 ('al-Mansuriyah').  \n",
    "This similarity suggests that the features learned by the model for class 1 are also applicable to the 'al-Mahdiyah' class, leading to consistent classification results.  \n",
    "Further investigation and analysis may be required to confirm this hypothesis and understand the underlying reasons for this similarity.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
